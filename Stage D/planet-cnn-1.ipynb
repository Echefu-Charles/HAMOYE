{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls /kaggle/input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n\nimport cv2\nfrom tqdm import tqdm","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = []\ny_train = []\n\ndf_train = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ndf_train.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"flatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n\nlabel_map = {l: i for i, l in enumerate(labels)}\ninv_label_map = {i: l for l, i in label_map.items()}\n\nfor f, tags in tqdm(df_train.values, miniters=1000):\n    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1 \n    x_train.append(cv2.resize(img, (64, 64)))\n    y_train.append(targets)\n    \ny_train = np.array(y_train, np.uint8)\nx_train = np.array(x_train, np.float16) / 255.\n\nprint(x_train.shape)\nprint(y_train.shape)","execution_count":3,"outputs":[{"output_type":"stream","text":"100%|██████████| 40479/40479 [01:55<00:00, 351.09it/s]\n","name":"stderr"},{"output_type":"stream","text":"(40479, 64, 64, 3)\n(40479, 17)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\nsample.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"  image_name                                  tags\n0     test_0  primary clear agriculture road water\n1     test_1  primary clear agriculture road water\n2     test_2  primary clear agriculture road water\n3     test_3  primary clear agriculture road water\n4     test_4  primary clear agriculture road water","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = sample[:40669]\n\ndf_test_extra = sample[40669:]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\nfor f in tqdm(df_test.image_name.values, miniters=1000):\n    img_test = cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(f))\n    test.append(cv2.resize(img_test, (64, 64)))\n    \nfor f in tqdm(df_test_extra.image_name.values, miniters=1000):\n    img_test2 = cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(f))\n    test.append(cv2.resize(img_test2, (64, 64)))\n    \nX_test = np.array(test, np.float16) / 255.\n\nprint(X_test.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"100%|██████████| 40669/40669 [01:59<00:00, 338.92it/s]\n100%|██████████| 20522/20522 [01:14<00:00, 275.88it/s]\n","name":"stderr"},{"output_type":"stream","text":"(61191, 64, 64, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.normalization import BatchNormalization","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(BatchNormalization(input_shape=(64, 64, 3)))\nmodel.add(Conv2D(8, 1, 1, padding='same', activation='relu'))\nmodel.add(Conv2D(16, 2, 2,padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, 3, 3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, 3, 3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, 3, 3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(17, activation='sigmoid'))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split = 35000\n\nx_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train,batch_size=128, epochs=100, verbose=1, \n          validation_data=(x_valid, y_valid), shuffle=True)\n","execution_count":12,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n274/274 [==============================] - 3s 12ms/step - loss: 0.2549 - accuracy: 0.1057 - val_loss: 0.2043 - val_accuracy: 0.0956\nEpoch 2/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1951 - accuracy: 0.1361 - val_loss: 0.1754 - val_accuracy: 0.1515\nEpoch 3/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1799 - accuracy: 0.1779 - val_loss: 0.1692 - val_accuracy: 0.1699\nEpoch 4/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1736 - accuracy: 0.1871 - val_loss: 0.1625 - val_accuracy: 0.1674\nEpoch 5/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1690 - accuracy: 0.2005 - val_loss: 0.1569 - val_accuracy: 0.1584\nEpoch 6/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1650 - accuracy: 0.1927 - val_loss: 0.1560 - val_accuracy: 0.1781\nEpoch 7/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1624 - accuracy: 0.1878 - val_loss: 0.1552 - val_accuracy: 0.1885\nEpoch 8/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1606 - accuracy: 0.1865 - val_loss: 0.1518 - val_accuracy: 0.2020\nEpoch 9/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1583 - accuracy: 0.1870 - val_loss: 0.1485 - val_accuracy: 0.1703\nEpoch 10/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1573 - accuracy: 0.1808 - val_loss: 0.1484 - val_accuracy: 0.1692\nEpoch 11/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1549 - accuracy: 0.1887 - val_loss: 0.1488 - val_accuracy: 0.1367\nEpoch 12/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1537 - accuracy: 0.1805 - val_loss: 0.1460 - val_accuracy: 0.1663\nEpoch 13/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1526 - accuracy: 0.1796 - val_loss: 0.1450 - val_accuracy: 0.1528\nEpoch 14/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1526 - accuracy: 0.1789 - val_loss: 0.1460 - val_accuracy: 0.1389\nEpoch 15/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1504 - accuracy: 0.1792 - val_loss: 0.1426 - val_accuracy: 0.1548\nEpoch 16/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1495 - accuracy: 0.1789 - val_loss: 0.1462 - val_accuracy: 0.1533\nEpoch 17/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1483 - accuracy: 0.1775 - val_loss: 0.1412 - val_accuracy: 0.1555\nEpoch 18/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1481 - accuracy: 0.1789 - val_loss: 0.1421 - val_accuracy: 0.1641\nEpoch 19/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1470 - accuracy: 0.1812 - val_loss: 0.1418 - val_accuracy: 0.1685\nEpoch 20/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1469 - accuracy: 0.1821 - val_loss: 0.1400 - val_accuracy: 0.1641\nEpoch 21/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1460 - accuracy: 0.1863 - val_loss: 0.1391 - val_accuracy: 0.1681\nEpoch 22/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1450 - accuracy: 0.1851 - val_loss: 0.1394 - val_accuracy: 0.1798\nEpoch 23/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1445 - accuracy: 0.1836 - val_loss: 0.1390 - val_accuracy: 0.1486\nEpoch 24/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1448 - accuracy: 0.1848 - val_loss: 0.1409 - val_accuracy: 0.1809\nEpoch 25/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1439 - accuracy: 0.1898 - val_loss: 0.1385 - val_accuracy: 0.1862\nEpoch 26/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1433 - accuracy: 0.1866 - val_loss: 0.1378 - val_accuracy: 0.1592\nEpoch 27/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1426 - accuracy: 0.1833 - val_loss: 0.1367 - val_accuracy: 0.1705\nEpoch 28/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1413 - accuracy: 0.1874 - val_loss: 0.1372 - val_accuracy: 0.1736\nEpoch 29/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1413 - accuracy: 0.1874 - val_loss: 0.1373 - val_accuracy: 0.1575\nEpoch 30/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1417 - accuracy: 0.1862 - val_loss: 0.1390 - val_accuracy: 0.1564\nEpoch 31/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1410 - accuracy: 0.1921 - val_loss: 0.1362 - val_accuracy: 0.1880\nEpoch 32/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1418 - accuracy: 0.1889 - val_loss: 0.1364 - val_accuracy: 0.1703\nEpoch 33/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1400 - accuracy: 0.1868 - val_loss: 0.1364 - val_accuracy: 0.1637\nEpoch 34/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1394 - accuracy: 0.1919 - val_loss: 0.1347 - val_accuracy: 0.1626\nEpoch 35/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1385 - accuracy: 0.1866 - val_loss: 0.1347 - val_accuracy: 0.1843\nEpoch 36/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1391 - accuracy: 0.1921 - val_loss: 0.1344 - val_accuracy: 0.1900\nEpoch 37/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1380 - accuracy: 0.1957 - val_loss: 0.1360 - val_accuracy: 0.1747\nEpoch 38/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1387 - accuracy: 0.1983 - val_loss: 0.1338 - val_accuracy: 0.1615\nEpoch 39/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1374 - accuracy: 0.1929 - val_loss: 0.1348 - val_accuracy: 0.2037\nEpoch 40/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1372 - accuracy: 0.1911 - val_loss: 0.1334 - val_accuracy: 0.1944\nEpoch 41/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1378 - accuracy: 0.1849 - val_loss: 0.1336 - val_accuracy: 0.1849\nEpoch 42/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1372 - accuracy: 0.1915 - val_loss: 0.1334 - val_accuracy: 0.1692\nEpoch 43/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1366 - accuracy: 0.1891 - val_loss: 0.1342 - val_accuracy: 0.1734\nEpoch 44/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1368 - accuracy: 0.1943 - val_loss: 0.1318 - val_accuracy: 0.1922\nEpoch 45/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1358 - accuracy: 0.1983 - val_loss: 0.1331 - val_accuracy: 0.1785\nEpoch 46/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1359 - accuracy: 0.1949 - val_loss: 0.1310 - val_accuracy: 0.1893\nEpoch 47/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1354 - accuracy: 0.1917 - val_loss: 0.1320 - val_accuracy: 0.2050\nEpoch 48/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1349 - accuracy: 0.1934 - val_loss: 0.1336 - val_accuracy: 0.1816\nEpoch 49/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1353 - accuracy: 0.1959 - val_loss: 0.1327 - val_accuracy: 0.1825\nEpoch 50/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1350 - accuracy: 0.1922 - val_loss: 0.1313 - val_accuracy: 0.1873\nEpoch 51/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1346 - accuracy: 0.1929 - val_loss: 0.1310 - val_accuracy: 0.1845\nEpoch 52/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1344 - accuracy: 0.1933 - val_loss: 0.1295 - val_accuracy: 0.1867\nEpoch 53/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1342 - accuracy: 0.1941 - val_loss: 0.1312 - val_accuracy: 0.1692\nEpoch 54/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1343 - accuracy: 0.1909 - val_loss: 0.1298 - val_accuracy: 0.1617\nEpoch 55/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1341 - accuracy: 0.1893 - val_loss: 0.1302 - val_accuracy: 0.1767\nEpoch 56/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1339 - accuracy: 0.1965 - val_loss: 0.1298 - val_accuracy: 0.1836\nEpoch 57/100\n","name":"stdout"},{"output_type":"stream","text":"274/274 [==============================] - 3s 10ms/step - loss: 0.1329 - accuracy: 0.1984 - val_loss: 0.1323 - val_accuracy: 0.1873\nEpoch 58/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1333 - accuracy: 0.1924 - val_loss: 0.1307 - val_accuracy: 0.1980\nEpoch 59/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1330 - accuracy: 0.1975 - val_loss: 0.1309 - val_accuracy: 0.1648\nEpoch 60/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1328 - accuracy: 0.1919 - val_loss: 0.1302 - val_accuracy: 0.1871\nEpoch 61/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1330 - accuracy: 0.1915 - val_loss: 0.1291 - val_accuracy: 0.2143\nEpoch 62/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1327 - accuracy: 0.1941 - val_loss: 0.1293 - val_accuracy: 0.1814\nEpoch 63/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1327 - accuracy: 0.1996 - val_loss: 0.1302 - val_accuracy: 0.1822\nEpoch 64/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1324 - accuracy: 0.1974 - val_loss: 0.1298 - val_accuracy: 0.2055\nEpoch 65/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1324 - accuracy: 0.1999 - val_loss: 0.1305 - val_accuracy: 0.1944\nEpoch 66/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1316 - accuracy: 0.1995 - val_loss: 0.1294 - val_accuracy: 0.1962\nEpoch 67/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1324 - accuracy: 0.1990 - val_loss: 0.1290 - val_accuracy: 0.1895\nEpoch 68/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1318 - accuracy: 0.2007 - val_loss: 0.1302 - val_accuracy: 0.1854\nEpoch 69/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1313 - accuracy: 0.2068 - val_loss: 0.1307 - val_accuracy: 0.1936\nEpoch 70/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1311 - accuracy: 0.2025 - val_loss: 0.1313 - val_accuracy: 0.1887\nEpoch 71/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1312 - accuracy: 0.2001 - val_loss: 0.1301 - val_accuracy: 0.1781\nEpoch 72/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1309 - accuracy: 0.1990 - val_loss: 0.1299 - val_accuracy: 0.1940\nEpoch 73/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1306 - accuracy: 0.2008 - val_loss: 0.1295 - val_accuracy: 0.1747\nEpoch 74/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1301 - accuracy: 0.1986 - val_loss: 0.1290 - val_accuracy: 0.1991\nEpoch 75/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1297 - accuracy: 0.2029 - val_loss: 0.1290 - val_accuracy: 0.1725\nEpoch 76/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1307 - accuracy: 0.1949 - val_loss: 0.1300 - val_accuracy: 0.1665\nEpoch 77/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1300 - accuracy: 0.1950 - val_loss: 0.1280 - val_accuracy: 0.1896\nEpoch 78/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1304 - accuracy: 0.1973 - val_loss: 0.1303 - val_accuracy: 0.1752\nEpoch 79/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1300 - accuracy: 0.2013 - val_loss: 0.1308 - val_accuracy: 0.1754\nEpoch 80/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1294 - accuracy: 0.1923 - val_loss: 0.1290 - val_accuracy: 0.1581\nEpoch 81/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1299 - accuracy: 0.2027 - val_loss: 0.1285 - val_accuracy: 0.1924\nEpoch 82/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1304 - accuracy: 0.1988 - val_loss: 0.1305 - val_accuracy: 0.1884\nEpoch 83/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1298 - accuracy: 0.1975 - val_loss: 0.1284 - val_accuracy: 0.1805\nEpoch 84/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1288 - accuracy: 0.2009 - val_loss: 0.1276 - val_accuracy: 0.1834\nEpoch 85/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1299 - accuracy: 0.1958 - val_loss: 0.1273 - val_accuracy: 0.1683\nEpoch 86/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1290 - accuracy: 0.1909 - val_loss: 0.1285 - val_accuracy: 0.1765\nEpoch 87/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1286 - accuracy: 0.1971 - val_loss: 0.1275 - val_accuracy: 0.2079\nEpoch 88/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1286 - accuracy: 0.1993 - val_loss: 0.1276 - val_accuracy: 0.1716\nEpoch 89/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1285 - accuracy: 0.1949 - val_loss: 0.1281 - val_accuracy: 0.1822\nEpoch 90/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1285 - accuracy: 0.1931 - val_loss: 0.1282 - val_accuracy: 0.1798\nEpoch 91/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1285 - accuracy: 0.1967 - val_loss: 0.1275 - val_accuracy: 0.1818\nEpoch 92/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1285 - accuracy: 0.1945 - val_loss: 0.1280 - val_accuracy: 0.1721\nEpoch 93/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1276 - accuracy: 0.1999 - val_loss: 0.1279 - val_accuracy: 0.1747\nEpoch 94/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1282 - accuracy: 0.1971 - val_loss: 0.1281 - val_accuracy: 0.1878\nEpoch 95/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1284 - accuracy: 0.1985 - val_loss: 0.1294 - val_accuracy: 0.1856\nEpoch 96/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1281 - accuracy: 0.1947 - val_loss: 0.1304 - val_accuracy: 0.1694\nEpoch 97/100\n274/274 [==============================] - 3s 11ms/step - loss: 0.1289 - accuracy: 0.1929 - val_loss: 0.1300 - val_accuracy: 0.1947\nEpoch 98/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1287 - accuracy: 0.1978 - val_loss: 0.1283 - val_accuracy: 0.1882\nEpoch 99/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1273 - accuracy: 0.2023 - val_loss: 0.1272 - val_accuracy: 0.1781\nEpoch 100/100\n274/274 [==============================] - 3s 10ms/step - loss: 0.1284 - accuracy: 0.1947 - val_loss: 0.1277 - val_accuracy: 0.1916\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(history.history['loss'], 'blue')\nplt.plot(history.history['val_loss'], 'red')\nplt.legend(['Training loss', 'Validation loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss Curves - With Reularization')","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"Text(0.5, 1.0, 'Loss Curves - With Reularization')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import fbeta_score\n\ndef optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n    def mf(x):\n        p2 = np.zeros_like(p)\n        for i in range(17):\n            p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n        score = fbeta_score(y, p2, beta=2, average='samples')\n        return score\n\n    x = [0.2]*17\n    for i in range(17):\n        best_i2 = 0\n        best_score = 0\n        for i2 in range(resolution):\n            i2 /= resolution\n            x[i] = i2\n            score = mf(x)\n            if score > best_score:\n                best_i2 = i2\n                best_score = score\n            \n        x[i] = best_i2\n        if verbose:\n            print(i, best_i2, best_score)\n\n    return x","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import fbeta_score\n\npred_valid = model.predict(x_valid, batch_size=128)\n\nprint(fbeta_score(y_valid, np.array(pred_valid) > 0.2, beta=2, average='samples'))","execution_count":15,"outputs":[{"output_type":"stream","text":"0.8847742153277119\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_valid = model.predict(x_valid, batch_size = 128, verbose=2)\nprint(fbeta_score(y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\nprint(\"Optimizing prediction threshold\")\nprint(optimise_f2_thresholds(y_valid, p_valid))","execution_count":17,"outputs":[{"output_type":"stream","text":"43/43 - 0s\n0.8847742153277119\nOptimizing prediction threshold\n0 0.22 0.884832033594529\n1 0.17 0.8851772176274965\n2 0.06 0.885826361047426\n3 0.09 0.8860307261740213\n4 0.24 0.8862930308111143\n5 0.23 0.8864071253595593\n6 0.18 0.8866504718002182\n7 0.22 0.8867378233032897\n8 0.36 0.8878880069205004\n9 0.21 0.8879237938186246\n10 0.1 0.8883199199211116\n11 0.05 0.8883199199211116\n12 0.12 0.8883199199211116\n13 0.04 0.8883199199211116\n14 0.15 0.8883345246697945\n15 0.19 0.8883345246697945\n16 0.22 0.888426093965861\n[0.22, 0.17, 0.06, 0.09, 0.24, 0.23, 0.18, 0.22, 0.36, 0.21, 0.1, 0.05, 0.12, 0.04, 0.15, 0.19, 0.22]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test, batch_size=128)\n\nfull_test = []\nfull_test.append(pred)\n\nresult = np.array(full_test[0])\nresult = pd.DataFrame(result, columns = labels)\nresult.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"      clear     water        cloudy  artisinal_mine  agriculture      road  \\\n0  0.998005  0.011120  6.991316e-09    5.529697e-14     0.007537  0.002048   \n1  0.997267  0.053253  4.366245e-08    2.038326e-09     0.066574  0.017048   \n2  0.000007  0.107056  3.313188e-05    3.615991e-07     0.099756  0.041175   \n3  0.998594  0.034929  1.289774e-08    2.012204e-10     0.023814  0.008648   \n4  0.017395  0.117930  3.693923e-01    2.887669e-05     0.149380  0.086211   \n\n   cultivation          haze   primary  habitation  partly_cloudy  \\\n0     0.002866  1.335887e-03  0.999996    0.000453       0.000366   \n1     0.040852  8.837673e-04  0.999983    0.004361       0.001073   \n2     0.024128  3.510264e-08  0.999922    0.003290       0.999958   \n3     0.013284  2.083995e-04  0.999993    0.002165       0.000637   \n4     0.029585  1.125835e-02  0.617373    0.015062       0.610748   \n\n     slash_burn  blooming  blow_down  selective_logging  conventional_mine  \\\n0  4.522549e-07  0.003331   0.000318           0.000202       5.796627e-12   \n1  2.028784e-04  0.022557   0.004906           0.006240       6.744332e-08   \n2  6.938402e-05  0.000015   0.000087           0.000097       1.852067e-06   \n3  2.237113e-05  0.016904   0.002304           0.003069       2.674759e-09   \n4  1.335309e-04  0.000027   0.000018           0.000237       2.345747e-05   \n\n   bare_ground  \n0     0.000074  \n1     0.001805  \n2     0.000364  \n3     0.000604  \n4     0.001737  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clear</th>\n      <th>water</th>\n      <th>cloudy</th>\n      <th>artisinal_mine</th>\n      <th>agriculture</th>\n      <th>road</th>\n      <th>cultivation</th>\n      <th>haze</th>\n      <th>primary</th>\n      <th>habitation</th>\n      <th>partly_cloudy</th>\n      <th>slash_burn</th>\n      <th>blooming</th>\n      <th>blow_down</th>\n      <th>selective_logging</th>\n      <th>conventional_mine</th>\n      <th>bare_ground</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.998005</td>\n      <td>0.011120</td>\n      <td>6.991316e-09</td>\n      <td>5.529697e-14</td>\n      <td>0.007537</td>\n      <td>0.002048</td>\n      <td>0.002866</td>\n      <td>1.335887e-03</td>\n      <td>0.999996</td>\n      <td>0.000453</td>\n      <td>0.000366</td>\n      <td>4.522549e-07</td>\n      <td>0.003331</td>\n      <td>0.000318</td>\n      <td>0.000202</td>\n      <td>5.796627e-12</td>\n      <td>0.000074</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.997267</td>\n      <td>0.053253</td>\n      <td>4.366245e-08</td>\n      <td>2.038326e-09</td>\n      <td>0.066574</td>\n      <td>0.017048</td>\n      <td>0.040852</td>\n      <td>8.837673e-04</td>\n      <td>0.999983</td>\n      <td>0.004361</td>\n      <td>0.001073</td>\n      <td>2.028784e-04</td>\n      <td>0.022557</td>\n      <td>0.004906</td>\n      <td>0.006240</td>\n      <td>6.744332e-08</td>\n      <td>0.001805</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000007</td>\n      <td>0.107056</td>\n      <td>3.313188e-05</td>\n      <td>3.615991e-07</td>\n      <td>0.099756</td>\n      <td>0.041175</td>\n      <td>0.024128</td>\n      <td>3.510264e-08</td>\n      <td>0.999922</td>\n      <td>0.003290</td>\n      <td>0.999958</td>\n      <td>6.938402e-05</td>\n      <td>0.000015</td>\n      <td>0.000087</td>\n      <td>0.000097</td>\n      <td>1.852067e-06</td>\n      <td>0.000364</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.998594</td>\n      <td>0.034929</td>\n      <td>1.289774e-08</td>\n      <td>2.012204e-10</td>\n      <td>0.023814</td>\n      <td>0.008648</td>\n      <td>0.013284</td>\n      <td>2.083995e-04</td>\n      <td>0.999993</td>\n      <td>0.002165</td>\n      <td>0.000637</td>\n      <td>2.237113e-05</td>\n      <td>0.016904</td>\n      <td>0.002304</td>\n      <td>0.003069</td>\n      <td>2.674759e-09</td>\n      <td>0.000604</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017395</td>\n      <td>0.117930</td>\n      <td>3.693923e-01</td>\n      <td>2.887669e-05</td>\n      <td>0.149380</td>\n      <td>0.086211</td>\n      <td>0.029585</td>\n      <td>1.125835e-02</td>\n      <td>0.617373</td>\n      <td>0.015062</td>\n      <td>0.610748</td>\n      <td>1.335309e-04</td>\n      <td>0.000027</td>\n      <td>0.000018</td>\n      <td>0.000237</td>\n      <td>2.345747e-05</td>\n      <td>0.001737</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\nthres2 = [0.22, 0.17, 0.06, 0.09, 0.24, 0.23, 0.18, 0.22, 0.36, 0.21, 0.1, 0.05, 0.12, 0.04, 0.15, 0.19, 0.22] \nprediction = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.loc[[i]]\n    a = a.apply(lambda x: x > thres2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    prediction.append(' '.join(list(a.index)))","execution_count":19,"outputs":[{"output_type":"stream","text":"100%|██████████| 61191/61191 [02:21<00:00, 431.68it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['tags'] = prediction\nsample.head()","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"  image_name                          tags\n0     test_0                 clear primary\n1     test_1                 clear primary\n2     test_2         primary partly_cloudy\n3     test_3                 clear primary\n4     test_4  cloudy primary partly_cloudy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>cloudy primary partly_cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('submission_4.csv', index=False)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n\nlabel_map = {l: i for i, l in enumerate(labels)}\ninv_label_map = {i: l for l, i in label_map.items()}\n\ny_train = []\nx_train = []\n\nfor f, tags in tqdm(df_train.values, miniters=1000):\n    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1 \n    x_train.append(cv2.resize(img, (64, 64)))\n    y_train.append(targets)\n    \ny_train = np.array(y_train, np.uint8)\nx_train = np.array(x_train, np.float16) / 255.\n\nprint(x_train.shape)\nprint(y_train.shape)","execution_count":5,"outputs":[{"output_type":"stream","text":"100%|██████████| 40479/40479 [01:58<00:00, 342.48it/s]\n","name":"stderr"},{"output_type":"stream","text":"(40479, 64, 64, 3)\n(40479, 17)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\nfor f in tqdm(df_test.image_name.values, miniters=1000):\n    img_test = cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(f))\n    test.append(cv2.resize(img_test, (64, 64)))\n    \nfor f in tqdm(df_test_extra.image_name.values, miniters=1000):\n    img_test2 = cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(f))\n    test.append(cv2.resize(img_test2, (64, 64)))\n    \nx_test = np.array(test, np.float16) / 255.\n\nprint(x_test.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"100%|██████████| 40669/40669 [02:28<00:00, 273.36it/s]\n100%|██████████| 20522/20522 [01:13<00:00, 278.13it/s]\n","name":"stderr"},{"output_type":"stream","text":"(61191, 64, 64, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nimport cv2\nfrom tqdm import tqdm\nfrom keras import optimizers\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import fbeta_score\nimport time","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.normalization import BatchNormalization","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import fbeta_score\n\ndef optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n    def mf(x):\n        p2 = np.zeros_like(p)\n        for i in range(17):\n            p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n        score = fbeta_score(y, p2, beta=2, average='samples')\n        return score\n\n    x = [0.2]*17\n    for i in range(17):\n        best_i2 = 0\n        best_score = 0\n        for i2 in range(resolution):\n            i2 /= resolution\n            x[i] = i2\n            score = mf(x)\n            if score > best_score:\n                best_i2 = i2\n                best_score = score\n            \n        x[i] = best_i2\n        if verbose:\n            print(i, best_i2, best_score)\n\n    return x\n ","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split = 35000\n\n# x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nfolds = 3\n\nnum_fold = 0\nsum_score = 0\n\nyfull_test = []\nyfull_train =[]\n\nkf = KFold(len(y_train), n_splits=nfolds, shuffle=True, random_state=1)\n\nfor train_index, test_index in kf.split(x_train):\n        start_time_model_fitting = time.time()\n        \n        X_train = x_train[train_index]\n        Y_train = y_train[train_index]\n        X_valid = x_train[test_index]\n        Y_valid = y_train[test_index]\n\n        num_fold += 1\n        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n        print('Split train: ', len(X_train), len(Y_train))\n        print('Split valid: ', len(X_valid), len(Y_valid))\n        \n        kfold_weights_path = os.path.join('', 'weights_kfold_' + str(num_fold) + '.h5')\n        \n        model = Sequential()\n        model.add(BatchNormalization(input_shape=(64, 64,3)))\n        model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\n#         model.add(Conv2D(32, (3, 3), activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\n#         model.add(Conv2D(64, (3, 3), activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\n#         model.add(Conv2D(128, (3, 3), activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n        model.add(Dropout(0.25))\n        \n#         model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\n#         model.add(Conv2D(256, (3, 3), activation='relu'))\n#         model.add(MaxPooling2D(pool_size=(2, 2)))\n#         model.add(Dropout(0.25))\n        \n        model.add(Flatten())\n        model.add(Dense(512, activation='relu'))\n        model.add(Dropout(0.3))\n        model.add(Dense(256, activation='relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(Dense(17, activation='sigmoid'))\n        \n        model.compile(loss='binary_crossentropy', \n                      optimizer='adam',\n                      metrics=['accuracy'])\n\n        callbacks = [\n            EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n        \n        hist = model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n          batch_size=128,verbose=2, epochs=10,callbacks=callbacks,\n          shuffle=True)\n        \n        if os.path.isfile(kfold_weights_path):\n            model.load_weights(kfold_weights_path)\n        \n        p_valid = model.predict(X_valid, batch_size = 128, verbose=2)\n        print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n        print(\"Optimizing prediction threshold\")\n        print(optimise_f2_thresholds(Y_valid, p_valid))\n        \n        p_test = model.predict(x_train, batch_size = 128, verbose=2)\n        yfull_train.append(p_test)\n        \n        p_test = model.predict(x_test, batch_size = 128, verbose=2)\n        yfull_test.append(p_test)\n        \n\n#         epochs_arr = [10, 5, 5]\n#         learn_rates = [0.001, 0.0001, 0.00001]\n\n#         for learn_rate, epochs in zip(learn_rates, epochs_arr):\n#             opt  = optimizers.Adam(lr=learn_rate)\n#             model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n#                           optimizer=opt,\n#                           metrics=['accuracy'])\n#             callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n#             ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n\n#             hist = model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n#                   batch_size=128,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n        \n#         if os.path.isfile(kfold_weights_path):\n#             model.load_weights(kfold_weights_path)\n        \n#         p_valid = model.predict(X_valid, batch_size = 128, verbose=2)\n#         print(fbeta_score(Y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))\n\n#         p_train = model.predict(x_train, batch_size =128, verbose=2)\n#         yfull_train.append(p_train)\n        \n#         p_test = model.predict(x_test, batch_size = 128, verbose=2)\n#         yfull_test.append(p_test)\n\n","execution_count":null,"outputs":[{"output_type":"stream","text":"Start KFold number 1 from 3\nSplit train:  40478 40478\nSplit valid:  1 1\nEpoch 1/10\n317/317 - 5s - loss: 0.3483 - accuracy: 0.4246 - val_loss: 0.0589 - val_accuracy: 1.0000\nEpoch 2/10\n317/317 - 5s - loss: 0.1686 - accuracy: 0.5356 - val_loss: 0.0339 - val_accuracy: 1.0000\nEpoch 3/10\n317/317 - 5s - loss: 0.1554 - accuracy: 0.5143 - val_loss: 0.0112 - val_accuracy: 1.0000\nEpoch 4/10\n317/317 - 5s - loss: 0.1491 - accuracy: 0.5328 - val_loss: 0.0046 - val_accuracy: 1.0000\nEpoch 5/10\n317/317 - 5s - loss: 0.1441 - accuracy: 0.5431 - val_loss: 0.0050 - val_accuracy: 1.0000\nEpoch 6/10\n317/317 - 5s - loss: 0.1411 - accuracy: 0.5353 - val_loss: 0.0040 - val_accuracy: 1.0000\nEpoch 7/10\n317/317 - 5s - loss: 0.1379 - accuracy: 0.5474 - val_loss: 0.0025 - val_accuracy: 1.0000\nEpoch 8/10\n317/317 - 5s - loss: 0.1342 - accuracy: 0.5529 - val_loss: 0.0020 - val_accuracy: 1.0000\nEpoch 9/10\n317/317 - 5s - loss: 0.1326 - accuracy: 0.5582 - val_loss: 0.0036 - val_accuracy: 1.0000\nEpoch 10/10\n317/317 - 5s - loss: 0.1296 - accuracy: 0.5699 - val_loss: 0.0023 - val_accuracy: 1.0000\n1/1 - 0s\n1.0\nOptimizing prediction threshold\n0 0.01 1.0\n1 0.01 1.0\n2 0.01 1.0\n3 0.0 1.0\n4 0.01 1.0\n5 0.01 1.0\n6 0.01 1.0\n7 0.01 1.0\n8 0.0 1.0\n9 0.01 1.0\n10 0.01 1.0\n11 0.01 1.0\n12 0.01 1.0\n13 0.01 1.0\n14 0.01 1.0\n15 0.01 1.0\n16 0.01 1.0\n[0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n317/317 - 2s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# result = np.array(yfull_test[0])\n# for i in range(1, nfolds):\n#     result += np.array(yfull_test[i])\n# result /= nfolds\n# result = pd.DataFrame(result, columns = labels)\n# result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.array(yfull_test[0])\nfor i in range(1, nfolds):\n    result += np.array(yfull_test[i])\nresult /= nfolds\nresult = pd.DataFrame(result, columns = labels)\nresult\n\nfrom tqdm import tqdm\nthres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\npreds = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.ix[[i]]\n    a = a.apply(lambda x: x > 0.2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    preds.append(' '.join(list(a.index)))\n    \ndf_test['tags'] = preds\ndf_test.to_csv('submission_keras_5_fold_CV_0.9136_LB_0.913.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looking at images\nfrom glob import glob\nimage_paths = sorted(glob(\"../input/planets-dataset/planet/planet/train-jpg/*.jpg\"))[0:1000]\nimage_names = list(map(lambda row: row.split(\"/\")[-1][:-4], image_paths))\nimage_names[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.imshow(plt.imread(image_paths[i]))\n    plt.title(str(train[train.image_name == image_names[i]].tags.values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.multiclass import OneVsRestClassifier\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import GridSearchCV, train_test_split\n# from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n# from sklearn.metrics import fbeta_score, precision_score, make_scorer, average_precision_score\n# import cv2\n# import warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sub = np.squeeze(np.array([cv2.resize(plt.imread('../input/test-jpg/{}.jpg'.format(name)), (rescaled_dim, rescaled_dim), cv2.INTER_LINEAR).reshape(1, -1) for name in sample['image_name'].values]))\nX_sub = MinMaxScaler().fit_transform(X_sub)\nX_sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_sub = clf.predict(X_sub)\nall_test_tags = []\nfor index in range(y_sub.shape[0]):\n    all_test_tags.append(' '.join(list(lb.classes_[np.where(y_sub[index, :] == 1)[0]])))\nall_test_tags[0:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = [plt.imread('../input/test-jpg/{}.jpg'.format(name)) for name in sample.head(20)['image_name'].values]\nplt.imshow(test_imgs[7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}